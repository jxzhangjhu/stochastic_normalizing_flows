{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from bgtorch.utils.types import assert_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bgtorch.nn.training import KLTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bgtorch.nn import DenseNet\n",
    "from bgtorch.nn.flow import (\n",
    "    SequentialFlow, \n",
    "    CouplingFlow, \n",
    "    AffineFlow, \n",
    "    SplitFlow,\n",
    "    MergeFlow,\n",
    "    InverseFlow, \n",
    "    SwapFlow\n",
    ")\n",
    "from bgtorch.nn.flow.transformer import AffineTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bgtorch import BoltzmannGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bgtorch.distribution.energy.base import Energy\n",
    "from bgtorch.distribution.energy import DoubleWellEnergy\n",
    "from bgtorch.distribution import NormalDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snf_code import InterpolatedEnergy, RNVP, boltzmann_generator_RNVP_MC\n",
    "from snf_code.analysis import sample_energy, statistical_efficiency\n",
    "from snf_code.imagetools import boltzmann_generator_NSF_MC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic functions\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_flow(flow, x0, inverse=False):\n",
    "    blocks = flow._blocks\n",
    "    samples = [x0]\n",
    "    x = [x0]\n",
    "    if inverse:\n",
    "        blocks = blocks[::-1]\n",
    "    for block in blocks:\n",
    "        *x, ddlogp = block(*x, inverse=inverse)\n",
    "        if not (isinstance(block, SplitFlow) or isinstance(block, SwapFlow) or isinstance(block, MergeFlow)):\n",
    "            #print(block)\n",
    "            x_np = [xi.detach().numpy() for xi in x]\n",
    "            samples.append(np.hstack(x_np))\n",
    "    if inverse:\n",
    "        samples = samples[::-1]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples(samples, weights=None, range=None, ax=None):\n",
    "    \"\"\" Plot sample histogram in 2D \"\"\"\n",
    "    samples = assert_numpy(samples)\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    ax.hist2d(\n",
    "        samples[:, 0], \n",
    "        -samples[:, 1],\n",
    "        weights=assert_numpy(weights) if weights is not None else weights,\n",
    "        bins=100,\n",
    "        norm=mpl.colors.LogNorm(),\n",
    "        range=range\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_uncertainty(target_energy, x, energies, w_x, w_energies):\n",
    "    X = torch.Tensor(np.vstack([x, np.zeros((1, len(x)))]).T)\n",
    "    E_target = target_energy.energy(X)[:, 0]\n",
    "    E_target -= E_target.min()\n",
    "    ######\n",
    "    E_target = E_target.detach().numpy()\n",
    "\n",
    "    # unweighted\n",
    "    E_mean = np.mean(energies, axis=0)\n",
    "    E_mean -= E_mean.min()\n",
    "\n",
    "    # weighted\n",
    "    Ew_mean = np.mean(w_energies, axis=0)\n",
    "    Ew_mean -= Ew_mean.min()\n",
    "\n",
    "    I = np.logical_and(hist_x > -2.25, hist_x < 2.25)\n",
    "    # bias\n",
    "    bias_unweighted = E_target - E_mean\n",
    "    #bias_unweighted = bias_unweighted.detach().numpy()\n",
    "    J = np.isfinite(bias_unweighted)\n",
    "    bias_unweighted = np.abs(bias_unweighted[I*J].mean())\n",
    "    bias_reweighted = E_target - Ew_mean\n",
    "    #bias_reweighted = bias_reweighted.detach().numpy()\n",
    "    J = np.isfinite(bias_reweighted)\n",
    "    bias_reweighted = np.abs(bias_reweighted[I*J].mean())\n",
    "    # uncertainty\n",
    "    std_unweighted = np.array(energies)[:, I*J].std(axis=0).mean()\n",
    "    std_reweighted = np.array(w_energies)[:, I*J].std(axis=0).mean()\n",
    "\n",
    "    return bias_unweighted, std_unweighted, bias_reweighted, std_reweighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_energy(target_energy, x, energies, w_x, w_energies, ylabel=False, nstd=2.0, figsize=(4, 4)):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    \n",
    "    X = torch.Tensor(np.vstack([np.linspace(-3, 3, num=100), np.zeros((1, 100))]).T)\n",
    "    E_target = target_energy.energy(X)\n",
    "    E_target -= E_target.min()\n",
    "    plt.plot(X[:, 0], E_target, linewidth=3, color='#444444')\n",
    "\n",
    "    # unweighted\n",
    "    E_mean = np.mean(energies, axis=0)\n",
    "    E_mean -= E_mean.min()\n",
    "    plt.errorbar(x, E_mean, nstd*np.std(energies, axis=0), color='red', linewidth=2)\n",
    "    \n",
    "    # weighted\n",
    "    Ew_mean = np.mean(w_energies, axis=0)\n",
    "    Ew_mean -= Ew_mean.min()\n",
    "    plt.errorbar(w_x, Ew_mean, nstd*np.std(w_energies, axis=0), color='green', linewidth=2)\n",
    "    \n",
    "    plt.ylim(-1, 14)\n",
    "    plt.xlabel('$x_1$')\n",
    "    if ylabel:\n",
    "        plt.ylabel('Energy (kT)')\n",
    "    else:\n",
    "        plt.yticks([])\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bgtorch.nn.flow.base import Flow\n",
    "\n",
    "class Adaptive_MetropolisMCFlow(Flow):\n",
    "    def __init__(self, energy_model, nsteps=1, stepsize=0.01):\n",
    "        \"\"\" Stochastic Flow layer that simulates Metropolis Monte Carlo\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.energy_model = energy_model\n",
    "        self.nsteps = nsteps\n",
    "        self.stepsize = torch.nn.Parameter(torch.ones(self.nsteps) * stepsize)\n",
    "    \n",
    "    def _forward(self, x, **kwargs):\n",
    "        \"\"\" Run a stochastic trajectory forward \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        x : PyTorch Tensor\n",
    "            Batch of input configurations\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        x' : PyTorch Tensor\n",
    "            Transformed configurations\n",
    "        dW : PyTorch Tensor\n",
    "            Nonequilibrium work done, always 0 for this process\n",
    "            \n",
    "        \"\"\"\n",
    "        E0 = self.energy_model.energy(x)\n",
    "        E = E0\n",
    "\n",
    "        for i in range(self.nsteps):\n",
    "            # proposal step\n",
    "            stepsize = torch.clamp(torch.abs(self.stepsize[i])+1e-2, 1e-2, 0.3) \n",
    "            dx = stepsize * torch.zeros_like(x).normal_()\n",
    "            xprop = x + dx\n",
    "            Eprop = self.energy_model.energy(xprop)\n",
    "            \n",
    "            # acceptance step\n",
    "            acc = (torch.rand(x.shape[0], 1) < torch.exp(-(Eprop - E))).float()  # selection variable: 0 or 1.\n",
    "            x = (1-acc) * x + acc * xprop\n",
    "            E = (1-acc) * E + acc * Eprop\n",
    "\n",
    "        # Work is energy difference\n",
    "        dW = E - E0\n",
    "        \n",
    "        return x, dW\n",
    "\n",
    "    def _inverse(self, x, **kwargs):\n",
    "        \"\"\" Same as forward \"\"\"\n",
    "        return self._forward(x, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snf_code import NSF\n",
    "\n",
    "def boltzmann_generator_NSF_adaptiveMC(prior, target, n_transform, \n",
    "                               n_bins=20,\n",
    "                               tail=1,\n",
    "                               width_nhidden=[64, 64, 64], \n",
    "                               height_nhidden=[64, 64, 64],\n",
    "                               slope_nhidden=[64, 64, 64],\n",
    "                               stochastic=False, diffuse_at_0=False, nrelax=20, stepsize=0.1):\n",
    "    # here we aggregate all layers of the flow\n",
    "    layers = []\n",
    "\n",
    "    # first flow\n",
    "    if diffuse_at_0:\n",
    "        layers.append(Adaptive_MetropolisMCFlow(prior, nsteps=nrelax, stepsize=stepsize))\n",
    "\n",
    "    # split\n",
    "    layers.append(SplitFlow(prior.dim//2))\n",
    "        \n",
    "    # RealNVP block\n",
    "    for i in range(n_transform):\n",
    "        # ic(x) -> v\n",
    "        layers.append(NSF([prior.dim//2] + width_nhidden + [n_bins * prior.dim//2], \n",
    "                          [prior.dim//2] + height_nhidden + [n_bins * prior.dim//2], \n",
    "                          [prior.dim//2] + slope_nhidden + [(n_bins + 1) * prior.dim//2], \n",
    "                          width_activation=torch.nn.ReLU(),\n",
    "                          height_activation=torch.nn.ReLU(),\n",
    "                          slope_activation=torch.nn.ReLU(),\n",
    "                          n_bins=n_bins,\n",
    "                          tail=tail\n",
    "                         ))\n",
    "        layers.append(SwapFlow())\n",
    "                            \n",
    "        # v -> ic(x)\n",
    "        layers.append(NSF([prior.dim//2] + width_nhidden + [n_bins * prior.dim//2], \n",
    "                          [prior.dim//2] + height_nhidden + [n_bins * prior.dim//2], \n",
    "                          [prior.dim//2] + slope_nhidden + [(n_bins + 1) * prior.dim//2], \n",
    "                          width_activation=torch.nn.ReLU(),\n",
    "                          height_activation=torch.nn.ReLU(),\n",
    "                          slope_activation=torch.nn.ReLU(),\n",
    "                          n_bins=n_bins,\n",
    "                          tail=tail\n",
    "                         ))\n",
    "        layers.append(SwapFlow())\n",
    "\n",
    "        if stochastic and i < n_transform-1:\n",
    "            layers.append(MergeFlow(prior.dim//2))\n",
    "            \n",
    "            lambda_ = i * 1.0/(n_transform-1)\n",
    "            energy_model = InterpolatedEnergy(prior, target, lambda_)\n",
    "            layers.append(Adaptive_MetropolisMCFlow(energy_model, nsteps=nrelax, stepsize=stepsize))\n",
    "        \n",
    "            layers.append(SplitFlow(prior.dim//2))\n",
    "\n",
    "    # merge\n",
    "    layers.append(MergeFlow(prior.dim//2))\n",
    "    \n",
    "    # final flow\n",
    "    if stochastic:\n",
    "        layers.append(Adaptive_MetropolisMCFlow(target, nsteps=nrelax, stepsize=stepsize))\n",
    "\n",
    "    # now define the flow as a sequence of all operations stored in layers\n",
    "    flexflow = SequentialFlow(layers)\n",
    "    \n",
    "    bg = BoltzmannGenerator(prior, flexflow, target)\n",
    "    \n",
    "    return bg\n",
    "\n",
    "def boltzmann_generator_RNVP_adaptiveMC(prior, target, n_transform, shift_nhidden=[64, 64, 64], scale_nhidden=[64, 64, 64],\n",
    "                                stochastic=False, diffuse_at_0=False, nrelax=20, stepsize=0.1):\n",
    "    # here we aggregate all layers of the flow\n",
    "    layers = []\n",
    "\n",
    "    # first flow\n",
    "    if diffuse_at_0:\n",
    "        layers.append(Adaptive_MetropolisMCFlow(prior, nsteps=nrelax, stepsize=stepsize))\n",
    "\n",
    "    # split\n",
    "    layers.append(SplitFlow(prior.dim//2))\n",
    "        \n",
    "    # RealNVP block\n",
    "    for i in range(n_transform):\n",
    "        # ic(x) -> v\n",
    "        layers.append(RNVP([prior.dim//2] + shift_nhidden + [prior.dim//2], \n",
    "                           [prior.dim//2] + scale_nhidden + [prior.dim//2], \n",
    "                           shift_activation=torch.nn.ReLU(), scale_activation=torch.nn.ReLU()))\n",
    "        layers.append(SwapFlow())\n",
    "                            \n",
    "        # v -> ic(x)\n",
    "        layers.append(RNVP([prior.dim//2] + shift_nhidden + [prior.dim//2], \n",
    "                           [prior.dim//2] + scale_nhidden + [prior.dim//2], \n",
    "                           shift_activation=torch.nn.ReLU(), scale_activation=torch.nn.ReLU()))\n",
    "        layers.append(SwapFlow())\n",
    "\n",
    "        if stochastic and i < n_transform-1:\n",
    "            layers.append(MergeFlow(prior.dim//2))\n",
    "            \n",
    "            lambda_ = i * 1.0/(n_transform-1)\n",
    "            energy_model = InterpolatedEnergy(prior, target, lambda_)\n",
    "            layers.append(Adaptive_MetropolisMCFlow(energy_model, nsteps=nrelax, stepsize=stepsize))\n",
    "        \n",
    "            layers.append(SplitFlow(prior.dim//2))\n",
    "\n",
    "    # merge\n",
    "    layers.append(MergeFlow(prior.dim//2))\n",
    "    \n",
    "    # final flow\n",
    "    if stochastic:\n",
    "        layers.append(Adaptive_MetropolisMCFlow(target, nsteps=nrelax, stepsize=stepsize))\n",
    "\n",
    "    # now define the flow as a sequence of all operations stored in layers\n",
    "    flexflow = SequentialFlow(layers)\n",
    "    \n",
    "    bg = BoltzmannGenerator(prior, flexflow, target)\n",
    "    \n",
    "    return bg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System and Data\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = NormalDistribution(2)\n",
    "target = DoubleWellEnergy(2, a=-0.5, b=-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bgtorch.distribution.sampling.mcmc import GaussianMCMCSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler_left = GaussianMCMCSampler(target, noise_std=0.2, init_state=torch.Tensor([[-2, 0]]), n_stride=10)\n",
    "x_left = sampler_left.sample(10000)\n",
    "\n",
    "sampler_right = GaussianMCMCSampler(target, noise_std=0.2, init_state=torch.Tensor([[2, 0]]), n_stride=10)\n",
    "x_right = sampler_right.sample(10000)\n",
    "\n",
    "x_both = torch.cat([x_left, x_right], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exact sample\n",
    "brute_sampler = GaussianMCMCSampler(target, init_state=torch.tensor([[-2., 0]]), noise_std=1.5, n_stride=1)\n",
    "x_brute = brute_sampler.sample(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias versus Variance\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = x_both\n",
    "data = x_brute\n",
    "\n",
    "bg = boltzmann_generator_RNVP_adaptiveMC(prior, target, n_transform=3, shift_nhidden=[64, 64], scale_nhidden=[64, 64],\n",
    "                                 stochastic=False)\n",
    "trainer = KLTrainer(bg, train_likelihood=True, train_energy=True,\n",
    "                    optim=torch.optim.Adam(bg.parameters(), lr=0.005))\n",
    "\n",
    "trainer.train(300, data=data, batchsize=128, w_likelihood=1, w_energy=0, n_print=0)\n",
    "trainer.train(300, data=data, batchsize=128, w_likelihood=0.5, w_energy=0.5, n_print=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_x, hists_y, whist_x, whists_y = sample_energy(bg, 100000, 20, nbins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and analyze several times (statistics)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_analyze(bg, data):\n",
    "    trainer = KLTrainer(bg, train_likelihood=True, train_energy=True,\n",
    "                        optim=torch.optim.Adam(bg.parameters(), lr=0.005))\n",
    "\n",
    "    trainer.train(300, data=data, batchsize=128, w_likelihood=1, w_energy=0, n_print=0)\n",
    "    trainer.train(300, data=data, batchsize=128, w_likelihood=0.5, w_energy=0.5, n_print=0)\n",
    "    #trainer_unbiased_MC.train(200, data=x_brute, batchsize=128, w_likelihood=0, w_energy=1, n_print=0)\n",
    "\n",
    "    se, ses = statistical_efficiency(bg, n_samples=50000, n_resample=1000)\n",
    "\n",
    "    hist_x, hists_y, whist_x, whists_y = sample_energy(bg, 100000, 20, nbins=30)\n",
    "    bias, std, bias_w, std_w = bias_uncertainty(target, hist_x, hists_y, whist_x, whists_y)\n",
    "    \n",
    "    return [bias, std, bias_w, std_w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t 0.7058265436867651 \t 0.24285042561351253 \t 0.03642463714201749 \t 0.4001397529677428\n",
      "1 \t 1.20210292286347 \t 0.17967980753823798 \t 0.010697787218761912 \t 0.3536563802698501\n",
      "2 \t 0.5983738072474113 \t 0.2530745178524027 \t 0.17192235488509597 \t 0.4774365786097161\n",
      "3 \t 0.816241714034399 \t 0.2512792582820743 \t 0.012649543115463624 \t 0.44707691434977975\n",
      "4 \t 0.9058474889640175 \t 0.21817359538527378 \t 0.06290970947061174 \t 0.3853170302215556\n",
      "5 \t 1.013574467913352 \t 0.18884381063325528 \t 0.020318324777225893 \t 0.35757088467448206\n",
      "6 \t 1.0969533669523523 \t 0.24097178821179557 \t 0.09411258169183633 \t 0.4393284623887627\n",
      "7 \t 1.0423406237926374 \t 0.2230604924877877 \t 0.057316522940934866 \t 0.45683455881278867\n",
      "8 \t 0.8411043582095621 \t 0.23241985055627434 \t 0.059627340863061505 \t 0.41590843358074575\n",
      "9 \t 1.146682073189269 \t 0.2142818060290248 \t 0.0019930040226666854 \t 0.40466536001841097\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# RNVP + MC unbiased\n",
    "stats_RNVP_MC = []\n",
    "for i in range(10):\n",
    "    bg_unbiased_MC = boltzmann_generator_RNVP_adaptiveMC(prior, target, n_transform=3, shift_nhidden=[64, 64], scale_nhidden=[64, 64],\n",
    "                                                 nrelax=20, stepsize=0.05, stochastic=True, diffuse_at_0=True)\n",
    "    stat = train_and_analyze(bg_unbiased_MC, x_brute[::10])\n",
    "    stats_RNVP_MC.append(stat)\n",
    "    print(i, '\\t', stat[0], '\\t', stat[1], '\\t', stat[2], '\\t', stat[3])    \n",
    "stats_RNVP_MC = np.array(stats_RNVP_MC)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Bias       Unc        Bias rew   Unc rew\n",
      "   [0.93690474 0.22446354 0.05279718 0.41379344]\n",
      "+- [0.18698912 0.02372998 0.04832732 0.03940226]\n",
      "\n",
      "sqrt(bias**2+std**2)\t 0.9656603492113291 +- 0.17664228314941716\n",
      "reweighted          \t 0.4193425302211292 +- 0.04530408383793004\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stats = stats_RNVP_MC\n",
    "print('    Bias       Unc        Bias rew   Unc rew')\n",
    "print('  ', np.mean(stats, axis=0))\n",
    "print('+-', np.std(stats, axis=0))\n",
    "print()\n",
    "ee_unweighted = np.sqrt(stats[:, 0]**2+stats[:, 1]**2)\n",
    "ee_reweighted = np.sqrt(stats[:, 2]**2+stats[:, 3]**2)\n",
    "print('sqrt(bias**2+std**2)\\t', np.mean(ee_unweighted), '+-', np.std(ee_unweighted))\n",
    "print('reweighted          \\t', np.mean(ee_reweighted), '+-', np.std(ee_reweighted))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
